# Case Study Template: SCULPT vs Vibe Coding

(C) 2026 byte5 GmbH

## Purpose
Test whether SCULPT is clearly superior to prompt-first vibe coding for a real development task.

This template is intentionally strict.  
If SCULPT does not show a strong advantage and no realistic improvement path exists, continuation should be reconsidered.

## 1) Experiment Scope

### Task
- Name:
- Description:
- Functional acceptance criteria:
  - [ ]
  - [ ]
  - [ ]

### Fixed Conditions
- LLM provider/model:
- Timebox per approach:
- Same developer:
- Same machine/environment:
- Number of repeat runs per approach:

## 2) Pre-Registered Expectations (Before Starting)
Write expected advantages of SCULPT before running the test:

1.  
2.  
3.  

## 3) Approaches

### A) SCULPT
- Script path:
- Build/run commands:

### B) Vibe Coding (Prompt-First)
- Prompt log path:
- Generated code path:
- Build/run commands:

## 4) Hard Metrics

| Metric | SCULPT | Vibe | Winner | Notes |
|---|---:|---:|---|---|
| Time to first working version (min) |  |  |  |  |
| Time to accepted final version (min) |  |  |  |  |
| Iterations until accepted |  |  |  |  |
| Reproducibility (stable runs / 5) |  |  |  |  |
| Regression count during changes |  |  |  |  |
| Change Request #1 effort (min) |  |  |  |  |
| Change Request #2 effort (min) |  |  |  |  |
| Token/cost footprint (if available) |  |  |  |  |

## 5) Developer UX Factors (Soft, But Decisive)
Score each factor from 1 (poor) to 5 (excellent).

| Factor | SCULPT | Vibe | Winner | Notes |
|---|---:|---:|---|---|
| Sense of control |  |  |  |  |
| Clarity of intent |  |  |  |  |
| Flow continuity |  |  |  |  |
| Cognitive load |  |  |  |  |
| Refinement comfort |  |  |  |  |
| Trust in outputs |  |  |  |  |
| Maintainability feel |  |  |  |  |
| Team readability |  |  |  |  |

## 6) Success Gate (Strict)
SCULPT passes only if all are true:

- [ ] Reproducibility is clearly higher than vibe coding.
- [ ] Change requests are implemented with fewer regressions and better stability.
- [ ] Developer UX total score is clearly better (not marginal).
- [ ] Final solution quality is at least equal, preferably better.

If one or more fail:
- [ ] Identify concrete improvement path (language/compiler/tooling).
- [ ] If no credible path exists, mark as No-Go.

## 7) Post-Experiment Findings

### Observed Results vs Expectations
1. Expected:
   Observed:
2. Expected:
   Observed:
3. Expected:
   Observed:

### Why SCULPT Won / Lost
- 

### Concrete Learnings
1.  
2.  
3.  

### Decision
- Outcome: `Go` / `Conditional Go` / `No-Go`
- Rationale:
- Next actions:

